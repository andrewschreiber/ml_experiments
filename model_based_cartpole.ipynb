{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from helpers.gym_render import display_frames_as_gif\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "from hyperdash import monitor_cell\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from hyperdash import monitor_cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda ready\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"Cuda ready\")\n",
    "    \n",
    "use_cuda = True\n",
    "FloatTensor = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if use_cuda else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if use_cuda else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "import os\n",
    "\n",
    "data_path = os.getcwd() + \"/data/\"\n",
    "frames = np.load(data_path + \"cartpole_frames.npy\")\n",
    "\n",
    "# def sliding_window(a, window=4, step_size=1):\n",
    "#     '''\n",
    "#     Input is list of `shape` np arrays of length N\n",
    "#     Output is N - 4 x 4 x `shape`\n",
    "#     '''\n",
    "#     end = a.shape[0]\n",
    "#     #return np.moveaxis(np.stack([a[i:end-window+i+1:step_size] for i in range(window)]), 0, -1)\n",
    "#     # TimeDistributed looks at axis 1\n",
    "#     return np.moveaxis(np.stack([a[i:end-window+i+1:step_size] for i in range(window)]), 0, 1)\n",
    "\n",
    "# def eps_to_stacked_window(a, offset=False):\n",
    "#     if offset:\n",
    "#         return np.vstack([sliding_window(np.stack(x))[1:] for x in a])\n",
    "#     else:\n",
    "#         return np.vstack([sliding_window(np.stack(x))[:-1] for x in a])\n",
    "\n",
    "# windowed_frames = np.expand_dims(eps_to_stacked_window(frames), -1)\n",
    "# windowed_frames_next = np.expand_dims(eps_to_stacked_window(frames, offset=True), -1)\n",
    "# # windowed_actions = eps_to_stacked_window(actions)\n",
    "# assert windowed_frames_next.shape == windowed_frames.shape\n",
    "# print(windowed_frames.shape)\n",
    "\n",
    "# stk_frames = torch.from_numpy(windowed_frames)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = frames.view()\n",
    "frms = []\n",
    "[[frms.append(frame) for frame in frs] for frs in f]\n",
    "len(frms)\n",
    "arr = np.array(frms)\n",
    "stk_frames = torch.from_numpy(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD8CAYAAACxUoU3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffa8cdc46d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(arr[90])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dim = 30\n",
    "X_dim = 150\n",
    "N = 1000\n",
    "train_batch_size = 2\n",
    "valid_batch_size = 100\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train       = data_utils.TensorDataset(stk_frames.float(), stk_frames.float())\n",
    "train_loader= data_utils.DataLoader(train, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Encoder\n",
    "class Q_net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(Q_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(X_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3gauss = nn.Linear(N, z_dim)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(self.lin1(x), p=0.25)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(self.lin2(x), p=0.25)\n",
    "        x = F.relu(x)\n",
    "        xgauss = self.lin3gauss(x)\n",
    "        return xgauss\n",
    "\n",
    "# Decoder\n",
    "class P_net(nn.Module):  \n",
    "    def __init__(self):\n",
    "        super(P_net, self).__init__()\n",
    "        self.lin1 = nn.Linear(z_dim, N)\n",
    "        self.lin2 = nn.Linear(N, N)\n",
    "        self.lin3 = nn.Linear(N, X_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.dropout(x, p=0.25)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = F.dropout(x, p=0.25)\n",
    "        x = self.lin3(x)\n",
    "        return F.sigmoid(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(10)  \n",
    "Q = Q_net()\n",
    "P = P_net()     # Encoder/Decoder  \n",
    "if use_cuda:  \n",
    "    Q = Q.cuda()\n",
    "    P = P.cuda()\n",
    "# Set learning rates\n",
    "gen_lr, reg_lr = 0.0006, 0.0008  \n",
    "# Set optimizators\n",
    "P_decoder = optim.Adam(P.parameters(), lr=gen_lr)  \n",
    "Q_encoder = optim.Adam(Q.parameters(), lr=gen_lr)  \n",
    "Q_generator = optim.Adam(Q.parameters(), lr=reg_lr)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Q_net()\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "129\n",
      "130\n",
      "131\n",
      "130\n",
      "128\n",
      "129\n",
      "129\n",
      "129\n",
      "129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-d0f49f99bde9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andrew/anaconda2/envs/p2/lib/python2.7/site-packages/torch/autograd/variable.pyc\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andrew/anaconda2/envs/p2/lib/python2.7/site-packages/torch/autograd/_functions/tensor.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_type\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/andrew/anaconda2/envs/p2/lib/python2.7/site-packages/torch/_utils.pyc\u001b[0m in \u001b[0;36m_type\u001b[0;34m(self, new_type, async)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot cast dense tensor to sparse tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masync\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%monitor_cell \"Model-based cartpole\"\n",
    "x = Variable(torch.randn(N, 150)).type(FloatTensor)\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = Variable(data).type(FloatTensor), Variable(target).type(FloatTensor).detach()\n",
    "        output = model(x)            \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(long(loss.data[0]))\n",
    "#     for param in model.parameters():\n",
    "#         print(param.var())\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-08-24 16:13:35,242] Cell magic `%%notify` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
